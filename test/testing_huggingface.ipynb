{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:17:40.219183800Z",
     "start_time": "2024-02-14T13:17:36.917903700Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoModelForImageClassification\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amar\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"microsoft/swinv2-base-patch4-window16-256\")\n",
    "classifier_model = AutoModelForImageClassification.from_pretrained(\"microsoft/swinv2-base-patch4-window16-256\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:17:42.693255200Z",
     "start_time": "2024-02-14T13:17:40.221188400Z"
    }
   },
   "id": "9f04c264314f4d04",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(4, 3, 64, 64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T15:00:55.488733900Z",
     "start_time": "2024-02-14T15:00:55.456629900Z"
    }
   },
   "id": "ed9f6195bc5867e9",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output = model(dummy_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:18:16.638567100Z",
     "start_time": "2024-02-14T13:18:14.201805100Z"
    }
   },
   "id": "47635f1fd4df180c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Swinv2ModelOutput(last_hidden_state=tensor([[[-0.0803, -0.0234, -0.1582,  ..., -0.0986, -0.0011, -0.0960],\n         [-0.0656, -0.1820, -0.1115,  ..., -0.1515, -0.1538, -0.2688],\n         [-0.0998,  0.0283, -0.0950,  ..., -0.1509, -0.1371, -0.1468],\n         [ 0.0907,  0.0003, -0.1615,  ..., -0.2218, -0.0874, -0.1254]],\n\n        [[-0.0556, -0.0632, -0.1737,  ..., -0.0891, -0.0492, -0.1333],\n         [-0.1872,  0.0496, -0.0690,  ..., -0.0999, -0.1099,  0.0319],\n         [-0.1471, -0.0031, -0.0725,  ..., -0.1007, -0.0143, -0.1815],\n         [-0.1286,  0.0717, -0.0755,  ..., -0.1538, -0.1152, -0.1157]],\n\n        [[-0.0784, -0.0250, -0.0873,  ..., -0.0989, -0.1463, -0.2100],\n         [-0.0441, -0.0614, -0.1123,  ..., -0.1135, -0.0937, -0.1441],\n         [-0.1517, -0.0231, -0.0558,  ..., -0.1646, -0.0602, -0.2877],\n         [-0.0904, -0.0202, -0.0871,  ..., -0.1745, -0.0975, -0.1295]],\n\n        [[-0.0824, -0.0309, -0.1365,  ..., -0.1018,  0.0193, -0.0958],\n         [-0.1056,  0.0027, -0.0686,  ..., -0.1054,  0.0802, -0.3083],\n         [-0.0811, -0.0259, -0.1058,  ..., -0.1911,  0.0173, -0.0874],\n         [-0.1756,  0.0282, -0.0925,  ..., -0.1903,  0.1286, -0.1952]]],\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0388, -0.0442, -0.1315,  ..., -0.1557, -0.0948, -0.1593],\n        [-0.1296,  0.0138, -0.0977,  ..., -0.1109, -0.0722, -0.0996],\n        [-0.0912, -0.0324, -0.0856,  ..., -0.1378, -0.0994, -0.1928],\n        [-0.1112, -0.0065, -0.1008,  ..., -0.1472,  0.0613, -0.1717]],\n       grad_fn=<ReshapeAliasBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:18:31.213964800Z",
     "start_time": "2024-02-14T13:18:31.160983700Z"
    }
   },
   "id": "cdbe26a8bca8044a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Swinv2ImageClassifierOutput(loss=None, logits=tensor([[-0.3284, -0.0325,  0.0598,  ..., -0.0114, -0.0010,  0.1994],\n        [-0.1365,  0.0166,  0.0262,  ...,  0.0643,  0.1996,  0.2237],\n        [-0.2058, -0.0294,  0.1991,  ...,  0.0333,  0.1115,  0.3279],\n        [-0.1488,  0.1560,  0.3246,  ...,  0.1174,  0.2852,  0.1444]],\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = classifier_model(dummy_input)\n",
    "logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:18:41.675739700Z",
     "start_time": "2024-02-14T13:18:38.968811800Z"
    }
   },
   "id": "e2097732b9e59512",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.3284, -0.0325,  0.0598,  ..., -0.0114, -0.0010,  0.1994],\n        [-0.1365,  0.0166,  0.0262,  ...,  0.0643,  0.1996,  0.2237],\n        [-0.2058, -0.0294,  0.1991,  ...,  0.0333,  0.1115,  0.3279],\n        [-0.1488,  0.1560,  0.3246,  ...,  0.1174,  0.2852,  0.1444]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:18:49.970020700Z",
     "start_time": "2024-02-14T13:18:49.950541200Z"
    }
   },
   "id": "f85901b55ebeee25",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Dinov2ForImageClassification, ConvNextV2ForImageClassification, ConvNextForImageClassification, SwinForImageClassification, Swinv2ForImageClassification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:19:51.702878800Z",
     "start_time": "2024-02-14T13:19:51.677797500Z"
    }
   },
   "id": "97f4db32f0a5528f",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "microsoft/dino-vits16-patch16-224 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:286\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[1;34m(response, endpoint_name)\u001B[0m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 286\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\requests\\models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[1;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[1;31mHTTPError\u001B[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/microsoft/dino-vits16-patch16-224/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRepositoryNotFoundError\u001B[0m                   Traceback (most recent call last)",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:385\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 385\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1368\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[0;32m   1366\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(head_call_error, RepositoryNotFoundError) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(head_call_error, GatedRepoError):\n\u001B[0;32m   1367\u001B[0m     \u001B[38;5;66;03m# Repo not found => let's raise the actual error\u001B[39;00m\n\u001B[1;32m-> 1368\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m head_call_error\n\u001B[0;32m   1369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1370\u001B[0m     \u001B[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001B[39;00m\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1238\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[0;32m   1237\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1238\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1239\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1245\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1246\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1247\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[0;32m   1248\u001B[0m     \u001B[38;5;66;03m# Cache the non-existence of the file and raise\u001B[39;00m\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1631\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001B[0m\n\u001B[0;32m   1630\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[1;32m-> 1631\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1632\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHEAD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1633\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1634\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1635\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1636\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1637\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1638\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1639\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1640\u001B[0m hf_raise_for_status(r)\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:385\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[1;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[1;32m--> 385\u001B[0m     response \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[0;32m    386\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    387\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    388\u001B[0m         follow_relative_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    389\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    390\u001B[0m     )\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:409\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[1;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[0;32m    408\u001B[0m response \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m--> 409\u001B[0m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:323\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[1;34m(response, endpoint_name)\u001B[0m\n\u001B[0;32m    315\u001B[0m     message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    316\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Client Error.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    317\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m make sure you are authenticated.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 323\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RepositoryNotFoundError(message, response) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m400\u001B[39m:\n",
      "\u001B[1;31mRepositoryNotFoundError\u001B[0m: 401 Client Error. (Request ID: Root=1-65ccbdfc-2e9b977c7ccb57cf3aaccb2f;93de2dcf-d7b0-45ed-9988-dc7b3c051e64)\n\nRepository Not Found for url: https://huggingface.co/microsoft/dino-vits16-patch16-224/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dino \u001B[38;5;241m=\u001B[39m \u001B[43mDinov2ForImageClassification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicrosoft/dino-vits16-patch16-224\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:2926\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2923\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m commit_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[0;32m   2925\u001B[0m         \u001B[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001B[39;00m\n\u001B[1;32m-> 2926\u001B[0m         resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2927\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2930\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2933\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2934\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2935\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2936\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2937\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2938\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2939\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2940\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[0;32m   2941\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Git\\chest-x-ray-classifier\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:406\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    401\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to access a gated repo.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mMake sure to request access at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    402\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and pass a token having permission to this repo either \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    404\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 406\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    407\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    408\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to pass a token \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    409\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`token=<your_token>`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RevisionNotFoundError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    414\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor this model name. Check the model page at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available revisions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: microsoft/dino-vits16-patch16-224 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "dino = Dinov2ForImageClassification.from_pretrained(\"microsoft/dino-patch16-224\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:19:58.163295Z",
     "start_time": "2024-02-14T13:19:56.624178100Z"
    }
   },
   "id": "5b840f2b30d7dfd6",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.models import swin_v2_b "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:56:00.578969700Z",
     "start_time": "2024-02-14T13:56:00.558380Z"
    }
   },
   "id": "e9df1a3202b0d61a",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "swin = swin_v2_b()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:56:06.981314700Z",
     "start_time": "2024-02-14T13:56:03.444889700Z"
    }
   },
   "id": "d22882b45c827af3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import SwinForImageClassification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:58:09.377703Z",
     "start_time": "2024-02-14T13:58:09.344430900Z"
    }
   },
   "id": "e59c1e340b669f01",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.8437,  0.0754,  1.3861,  ...,  0.1153, -0.0851,  0.5369],\n        [ 1.1750, -0.1091, -0.7431,  ..., -0.3298,  0.1594,  0.7720],\n        [-0.6534, -0.8041,  0.4562,  ...,  0.0322,  1.0977,  0.9998],\n        [-0.7494, -0.0963, -0.0968,  ..., -0.5811,  0.2786, -0.7411]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(dummy_input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T15:00:59.463964200Z",
     "start_time": "2024-02-14T15:00:58.741992900Z"
    }
   },
   "id": "2e43933e285369d5",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0803, -0.0234, -0.1582,  ..., -0.0986, -0.0011, -0.0960],\n         [-0.0656, -0.1820, -0.1115,  ..., -0.1515, -0.1538, -0.2688],\n         [-0.0998,  0.0283, -0.0950,  ..., -0.1509, -0.1371, -0.1468],\n         [ 0.0907,  0.0003, -0.1615,  ..., -0.2218, -0.0874, -0.1254]],\n\n        [[-0.0556, -0.0632, -0.1737,  ..., -0.0891, -0.0492, -0.1333],\n         [-0.1872,  0.0496, -0.0690,  ..., -0.0999, -0.1099,  0.0319],\n         [-0.1471, -0.0031, -0.0725,  ..., -0.1007, -0.0143, -0.1815],\n         [-0.1286,  0.0717, -0.0755,  ..., -0.1538, -0.1152, -0.1157]],\n\n        [[-0.0784, -0.0250, -0.0873,  ..., -0.0989, -0.1463, -0.2100],\n         [-0.0441, -0.0614, -0.1123,  ..., -0.1135, -0.0937, -0.1441],\n         [-0.1517, -0.0231, -0.0558,  ..., -0.1646, -0.0602, -0.2877],\n         [-0.0904, -0.0202, -0.0871,  ..., -0.1745, -0.0975, -0.1295]],\n\n        [[-0.0824, -0.0309, -0.1365,  ..., -0.1018,  0.0193, -0.0958],\n         [-0.1056,  0.0027, -0.0686,  ..., -0.1054,  0.0802, -0.3083],\n         [-0.0811, -0.0259, -0.1058,  ..., -0.1911,  0.0173, -0.0874],\n         [-0.1756,  0.0282, -0.0925,  ..., -0.1903,  0.1286, -0.1952]]],\n       grad_fn=<NativeLayerNormBackward0>)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output = output[0]\n",
    "pooled_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:58:23.408247500Z",
     "start_time": "2024-02-14T13:58:23.383851100Z"
    }
   },
   "id": "e44f504f18cd8dd4",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.models import swin_v2_b\n",
    "from torch.nn import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:43:21.856710400Z",
     "start_time": "2024-02-14T14:43:21.843324800Z"
    }
   },
   "id": "96f5dafd24439006",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SwinTransformer(\n  (features): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n      (1): Permute()\n      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    )\n    (1): Sequential(\n      (0): SwinTransformerBlockV2(\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=4, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=512, out_features=128, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlockV2(\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=128, out_features=384, bias=True)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=4, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=512, out_features=128, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (2): PatchMergingV2(\n      (reduction): Linear(in_features=512, out_features=256, bias=False)\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n    (3): Sequential(\n      (0): SwinTransformerBlockV2(\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=8, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=256, out_features=1024, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=1024, out_features=256, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlockV2(\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=256, out_features=768, bias=True)\n          (proj): Linear(in_features=256, out_features=256, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=8, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=256, out_features=1024, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=1024, out_features=256, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (4): PatchMergingV2(\n      (reduction): Linear(in_features=1024, out_features=512, bias=False)\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (5): Sequential(\n      (0): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (12): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (13): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (14): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (15): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (16): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (17): SwinTransformerBlockV2(\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=16, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (6): PatchMergingV2(\n      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (7): Sequential(\n      (0): SwinTransformerBlockV2(\n        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=32, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=4096, out_features=1024, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): SwinTransformerBlockV2(\n        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): ShiftedWindowAttentionV2(\n          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (cpb_mlp): Sequential(\n            (0): Linear(in_features=2, out_features=512, bias=True)\n            (1): ReLU(inplace=True)\n            (2): Linear(in_features=512, out_features=32, bias=False)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=4096, out_features=1024, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  (permute): Permute()\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (head): Linear(in_features=1024, out_features=1000, bias=True)\n)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = swin_v2_b()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:57:35.799699700Z",
     "start_time": "2024-02-14T14:57:33.185299800Z"
    }
   },
   "id": "b40549350ffa2970",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 2, 2, 1024])\n",
      "torch.Size([4, 2, 2, 1024])\n"
     ]
    }
   ],
   "source": [
    "partial_a = Sequential(*list(model.children())[:-3])\n",
    "partial_b = Sequential(*list(model.children())[:-4])\n",
    "partial_c = model.features\n",
    "\n",
    "print(partial_a(dummy_input).shape)\n",
    "print(partial_b(dummy_input).shape)\n",
    "print(partial_c(dummy_input).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T15:01:04.602105300Z",
     "start_time": "2024-02-14T15:01:02.673129100Z"
    }
   },
   "id": "9671d6bcf87d95e",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Swinv2Model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:44:59.092803900Z",
     "start_time": "2024-02-14T14:44:59.071962500Z"
    }
   },
   "id": "567259e60fbd89b9",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hg_swin = Swinv2Model.from_pretrained(\"microsoft/swinv2-base-patch4-window16-256\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:45:27.086519800Z",
     "start_time": "2024-02-14T14:45:25.736866600Z"
    }
   },
   "id": "56df3b03780ca7dd",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swinv2Model(\n",
      "  (embeddings): Swinv2Embeddings(\n",
      "    (patch_embeddings): Swinv2PatchEmbeddings(\n",
      "      (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Swinv2Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Swinv2Stage(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x Swinv2Layer(\n",
      "            (attention): Swinv2Attention(\n",
      "              (self): Swinv2SelfAttention(\n",
      "                (continuous_position_bias_mlp): Sequential(\n",
      "                  (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "                )\n",
      "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (key): Linear(in_features=128, out_features=128, bias=False)\n",
      "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (output): Swinv2SelfOutput(\n",
      "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (drop_path): Swinv2DropPath(p=0.1)\n",
      "            (intermediate): Swinv2Intermediate(\n",
      "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): Swinv2Output(\n",
      "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (downsample): Swinv2PatchMerging(\n",
      "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Swinv2Stage(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x Swinv2Layer(\n",
      "            (attention): Swinv2Attention(\n",
      "              (self): Swinv2SelfAttention(\n",
      "                (continuous_position_bias_mlp): Sequential(\n",
      "                  (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "                )\n",
      "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (key): Linear(in_features=256, out_features=256, bias=False)\n",
      "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (output): Swinv2SelfOutput(\n",
      "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (drop_path): Swinv2DropPath(p=0.1)\n",
      "            (intermediate): Swinv2Intermediate(\n",
      "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): Swinv2Output(\n",
      "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (downsample): Swinv2PatchMerging(\n",
      "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Swinv2Stage(\n",
      "        (blocks): ModuleList(\n",
      "          (0-17): 18 x Swinv2Layer(\n",
      "            (attention): Swinv2Attention(\n",
      "              (self): Swinv2SelfAttention(\n",
      "                (continuous_position_bias_mlp): Sequential(\n",
      "                  (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "                )\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=False)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (output): Swinv2SelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (drop_path): Swinv2DropPath(p=0.1)\n",
      "            (intermediate): Swinv2Intermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): Swinv2Output(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (downsample): Swinv2PatchMerging(\n",
      "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Swinv2Stage(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x Swinv2Layer(\n",
      "            (attention): Swinv2Attention(\n",
      "              (self): Swinv2SelfAttention(\n",
      "                (continuous_position_bias_mlp): Sequential(\n",
      "                  (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                  (1): ReLU(inplace=True)\n",
      "                  (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "                )\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (output): Swinv2SelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (drop_path): Swinv2DropPath(p=0.1)\n",
      "            (intermediate): Swinv2Intermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): Swinv2Output(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (pooler): AdaptiveAvgPool1d(output_size=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(hg_swin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:45:29.368222900Z",
     "start_time": "2024-02-14T14:45:29.346283700Z"
    }
   },
   "id": "bc211c3f8c95664d",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Swinv2ModelOutput(last_hidden_state=tensor([[[-1.2145e-01, -1.4345e-01, -1.9764e-01,  ..., -7.1411e-02,\n          -7.4332e-02, -4.5897e-01],\n         [-1.5069e-01,  1.8928e-03, -3.5361e-02,  ..., -1.5503e-01,\n          -3.3835e-02, -6.1100e-02],\n         [-1.1029e-01, -1.5225e-02, -6.6422e-02,  ..., -1.0347e-01,\n          -2.2200e-02, -2.4258e-04],\n         [-9.1041e-02,  4.2028e-02, -4.7165e-02,  ..., -1.2793e-01,\n           1.3967e-02, -5.3806e-02]],\n\n        [[-1.4003e-01, -9.2948e-02, -1.3430e-01,  ..., -9.0222e-02,\n          -1.6096e-01, -2.4195e-01],\n         [-2.2246e-01, -5.3050e-02, -1.3448e-01,  ..., -1.4318e-01,\n          -1.0729e-01, -1.8262e-01],\n         [-1.1345e-01,  1.0924e-02, -8.0022e-02,  ..., -6.9763e-02,\n          -7.1561e-02,  1.1568e-02],\n         [ 1.1089e-02,  4.0826e-02, -2.6907e-02,  ..., -2.1621e-01,\n          -1.0172e-02, -9.2461e-02]],\n\n        [[-1.6711e-01, -6.8040e-02, -1.4898e-01,  ..., -9.6711e-02,\n          -1.6453e-01, -3.0842e-01],\n         [-1.8602e-01,  1.7620e-02, -6.2683e-02,  ..., -1.0820e-01,\n          -2.0072e-01, -7.7343e-02],\n         [-5.5710e-02, -3.0151e-02, -1.4409e-01,  ..., -5.4306e-02,\n          -4.4184e-02, -1.0709e-01],\n         [-6.6568e-02,  1.3331e-03, -1.3288e-01,  ..., -1.7150e-01,\n          -8.3778e-02, -9.6980e-02]],\n\n        [[-1.1600e-01, -9.6608e-02, -1.4777e-01,  ..., -1.2579e-01,\n          -1.9238e-01, -3.7884e-01],\n         [-9.1798e-02, -1.8526e-01, -9.4976e-02,  ..., -1.4441e-01,\n          -6.6044e-01, -2.9291e-01],\n         [-9.0079e-02, -2.1062e-02, -6.7515e-02,  ..., -9.5589e-02,\n          -1.4080e-01,  4.7610e-02],\n         [-1.3356e-01, -6.4624e-02, -5.6411e-02,  ..., -1.2960e-01,\n          -2.1372e-01, -1.9667e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.2145e-01, -1.5069e-01, -1.1029e-01,  ..., -6.1100e-02,\n         -2.4258e-04, -5.3806e-02],\n        [-1.4003e-01, -2.2246e-01, -1.1345e-01,  ..., -1.8262e-01,\n          1.1568e-02, -9.2461e-02],\n        [-1.6711e-01, -1.8602e-01, -5.5710e-02,  ..., -7.7343e-02,\n         -1.0709e-01, -9.6980e-02],\n        [-1.1600e-01, -9.1798e-02, -9.0079e-02,  ..., -2.9291e-01,\n          4.7610e-02, -1.9667e-01]], grad_fn=<UnsafeViewBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = hg_swin(dummy_input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T15:01:09.775978400Z",
     "start_time": "2024-02-14T15:01:06.613708300Z"
    }
   },
   "id": "9a1643d561ac9b8c",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 4096])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T15:01:11.793117200Z",
     "start_time": "2024-02-14T15:01:11.758088400Z"
    }
   },
   "id": "ce58f88c0ce8ee68",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hg_swin.pooler = torch.nn.Identity()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:47:37.840697200Z",
     "start_time": "2024-02-14T14:47:37.812227600Z"
    }
   },
   "id": "56a6bf343ab29c28",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Swinv2ModelOutput(last_hidden_state=tensor([[[-0.0803, -0.0234, -0.1582,  ..., -0.0986, -0.0011, -0.0960],\n         [-0.0656, -0.1820, -0.1115,  ..., -0.1515, -0.1538, -0.2688],\n         [-0.0998,  0.0283, -0.0950,  ..., -0.1509, -0.1371, -0.1468],\n         [ 0.0907,  0.0003, -0.1615,  ..., -0.2218, -0.0874, -0.1254]],\n\n        [[-0.0556, -0.0632, -0.1737,  ..., -0.0891, -0.0492, -0.1333],\n         [-0.1872,  0.0496, -0.0690,  ..., -0.0999, -0.1099,  0.0319],\n         [-0.1471, -0.0031, -0.0725,  ..., -0.1007, -0.0143, -0.1815],\n         [-0.1286,  0.0717, -0.0755,  ..., -0.1538, -0.1152, -0.1157]],\n\n        [[-0.0784, -0.0250, -0.0873,  ..., -0.0989, -0.1463, -0.2100],\n         [-0.0441, -0.0614, -0.1123,  ..., -0.1135, -0.0937, -0.1441],\n         [-0.1517, -0.0231, -0.0558,  ..., -0.1646, -0.0602, -0.2877],\n         [-0.0904, -0.0202, -0.0871,  ..., -0.1745, -0.0975, -0.1295]],\n\n        [[-0.0824, -0.0309, -0.1365,  ..., -0.1018,  0.0193, -0.0958],\n         [-0.1056,  0.0027, -0.0686,  ..., -0.1054,  0.0802, -0.3083],\n         [-0.0811, -0.0259, -0.1058,  ..., -0.1911,  0.0173, -0.0874],\n         [-0.1756,  0.0282, -0.0925,  ..., -0.1903,  0.1286, -0.1952]]],\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0803, -0.0656, -0.0998,  ..., -0.2688, -0.1468, -0.1254],\n        [-0.0556, -0.1872, -0.1471,  ...,  0.0319, -0.1815, -0.1157],\n        [-0.0784, -0.0441, -0.1517,  ..., -0.1441, -0.2877, -0.1295],\n        [-0.0824, -0.1056, -0.0811,  ..., -0.3083, -0.0874, -0.1952]],\n       grad_fn=<UnsafeViewBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = hg_swin(dummy_input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:47:46.172150Z",
     "start_time": "2024-02-14T14:47:43.786008100Z"
    }
   },
   "id": "2bf9291d4eb15935",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 4096])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:48:52.384485300Z",
     "start_time": "2024-02-14T14:48:52.354237300Z"
    }
   },
   "id": "8ab2e785d67b2ba1",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f86856b60e97696"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
